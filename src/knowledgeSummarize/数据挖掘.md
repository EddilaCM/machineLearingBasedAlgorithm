###**数据挖掘**
1. 数据的统计应用
2. 刻画用户画像
3. 预测

深度学习是一个黑盒子，解释性不强！！！

**语言要求**（阿里）：Java+SQL+Python+shell

### 中心极限定理(the central limit theorem)
1、什么是中心极限定理？

对于N个独立同分布（但分布未知），期望和方差已定的随机变量，选样本容量为m抽样无数次，抽样的均值是满足正态分布的【一种分布】

-----这些随机变量的均值（或者和）的分布是服从正态分布的



### 大数定律（the weak law of large numbers）

------证明了当数据很大的时候，平均值就是期望值！！！【一个值】

![中心极限定理](https://i.imgur.com/17FXkkd.jpg)

大数定律和中心极限定理的共同点：
   
------独立同分布的随机变量的和的**渐进表现**（极限）

区别：

![](https://i.imgur.com/t1ZakVz.jpg)

e.g. 一滴水从高空落下，经过一个随机分布的风向后，落在地上

大数定律指出：无论风向分布是什么，所有点距离垂直落下的点的距离应该等于一个值，这个值就是期望

中心极限定理指出：无论风向分布是什么，每个样本（每一滴水）距离期望的分布是一个正态分布。


**范数：**
一种具有才“长度”概念的函数（一种映射关系），把不能比较的变成可以比较的。比如，空间中的两个点（1,1），（0,3）通过范数分别映射到实数（根号2）和3，这样就能比较了。
## **机器学习常见知识点总结：** ##
1. 基础知识点：
   - **MSE**（mean square error 均方误差）
   - 
   
	定义： 指参数的估计值与真实值之差平方的期望；

	可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度。 
    
	![MSE](https://i.imgur.com/fMugCNL.gif)

   - **RMSE**（均方根误差）
   - 
      
      均方误差的算术平方根  

	![RMSE](https://i.imgur.com/9o49Vwf.gif)   

   - **LSM**（least square method最小二乘法）
   - 
   ![最小二乘法](https://i.imgur.com/V233hPV.jpg)
   
	定义：用（估计值-真实值）的平方和

     （估计值-真实值）	在回归分析中成为**残差**

	最小二乘法实际上就是投影矩阵（向量）的计算！！！使得投影的距离最小。

	投影矩阵：

	性质：![投影矩阵性质1](https://i.imgur.com/b8MGwA1.gif)，![投影矩阵性质2](https://i.imgur.com/xmHzRwB.gif)
   - **MLE**（Maximum LikelihoodEstimation极大似然估计）
   - 
	随机抽样取出一组样本数据，进行参加估计，使得抽出的这组样本的发生概率最大【求极值问题，即转化为求一阶导数为0 的点】

	联合概率（一组样本的中每个属性发生概率的连乘）——> 取对数（将乘法变成加法，便于计算）——>求一阶导数为0 ——>求出参数的估计值。

   - **LMS算法**（least mean square最小均方算法）
   - **QP**(Quadratic Programming 二次规划)
   - **CP**(Conditional Probability条件概率)
   - 
	**有条件的发生**（不是自成一派，所以不能自己想怎么干就怎么干！“孔融让梨”）

	![条件概率](https://i.imgur.com/dog6XWC.jpg)
	
	B发生的前提条件下，A发生的概率（在韦恩图中表示，A、B相交的部分在B中所占的比例）~~

   - **JP**(Joint Probability 联合概率)
   - 
	**多个条件同时发生的概率**

	![联合概率](https://i.imgur.com/QHPGTV9.gif)【可以推出**条件概率**】

	特别地，当A，B独立不相关时，![不相关时联合概率](https://i.imgur.com/aIjETRZ.gif)
	
   - **MP**(Marginal Probability边缘概率)
   - 
	**仅与单个变量有关的概率**（不管是不是和别人一起有关系的发生，还是自成一派单独发生，只要该变量发生就OK）

   - **Bayesian Formula**(贝叶斯公式)
   - **L1 /L2 Regularization**(L1/L2正则，以及更多的，现在比较火的L2.5正则等)
   - **GD**(Gradient Descent 梯度下降)
   - **SGD**(Stochastic GradientDescent 随机梯度下降)
   - **Eigenvalue**(特征值)
   - **Eigenvector**(特征向量)
   - **QR-decomposition**(QR分解)
   - **Quantile** (分位数)
   - **Covariance**(协方差矩阵)。

2. 常见分布：
	+ Discrete Distribution(离散型分布)：
		+ Bernoulli Distribution/Binomial(贝努利分步/二项分布)
		+ Negative BinomialDistribution(负二项分布)
		+ Multinomial Distribution(多式分布)
		+ Geometric Distribution(几何分布)
		+ Hypergeometric Distribution(超几何分布)
		+ Poisson Distribution (泊松分布)
	+ ContinuousDistribution (连续型分布)：
		+ Uniform Distribution(均匀分布)
		+ Normal Distribution/GaussianDistribution(正态分布/高斯分布)
		+ Exponential Distribution(指数分布)
		+ Lognormal Distribution(对数正态分布)
		+ Gamma Distribution(Gamma分布)
		+ Beta Distribution(Beta分布)
		+ Dirichlet Distribution(狄利克雷分布)
		+ Rayleigh Distribution(瑞利分布)
		+ Cauchy Distribution(柯西分布)
		+ Weibull Distribution (韦伯分布)
	+ Three Sampling Distribution(三大抽样分布)：
		+ Chi-square Distribution(卡方分布)
		+ t-distribution(t-distribution)
		+ F-distribution(F-分布)
3. Data Pre-processing(数据预处理)：
	- MissingValue Imputation(缺失值填充)
	- Discretization(离散化)
	- Mapping(映射)
	- Normalization(归一化/标准化)。
	- Sampling(采样)：
		+ SimpleRandom Sampling(简单随机采样)
		+ Offline Sampling(离线等可能K采样)
		+ Online Sampling(在线等可能K采样)
		+ Ratio-based Sampling(等比例随机采样)
		+ Acceptance-rejection Sampling(接受-拒绝采样)
		+ Importance Sampling(重要性采样)
		+ MCMC(Markov Chain MonteCarlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting& Gibbs)。